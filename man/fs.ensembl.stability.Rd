% Generated by roxygen2 (4.0.0): do not edit by hand
\name{fs.ensembl.stability}
\alias{fs.ensembl.stability}
\title{Ensemble Classification & Feature Selection}
\usage{
fs.ensembl.stability(X, Y, method, k = 10, p = 0.9,
  f = ceiling(ncol(X)/10), bags = 40, aggregation.metric = "CLA",
  stability.metric = "jaccard", optimize = TRUE,
  optimize.resample = FALSE, tuning.grid = NULL, k.folds = if (optimize)
  10 else NULL, repeats = if (k.folds == "LOO") NULL else if (optimize) 3 else
  NULL, resolution = if (optimize) 3 else NULL, metric = "Accuracy",
  model.features = FALSE, allowParallel = FALSE, verbose = FALSE, ...)
}
\arguments{
\item{X}{A matrix containing numeric values of each feature}

\item{Y}{A factor vector containing group membership of samples}

\item{method}{A vector listing models to be fit.
Available options are \code{"plsda"} (Partial Least Squares Discriminant Analysis),
 \code{"rf"} (Random Forest), \code{"gbm"} (Gradient Boosting Machine),
 \code{"svm"} (Support Vector Machines), \code{"glmnet"} (Elastic-net Generalized Linear Model),
 and \code{"pam"} (Prediction Analysis of Microarrays)}

\item{k}{Number of bootstrapped interations}

\item{p}{Percent of data to by 'trained'}

\item{f}{Number of features desired.  Default is top 10%
\code{"f = ceiling(ncol(variables)/10)"}.
If rank correlation is desired, set \code{"f = NULL"}}

\item{bags}{Number of iterations for ensemble bagging.  Default \code{"bags = 40"}}

\item{aggregation.metric}{String indicating which aggregation metric for features selected during bagging.
#' Avialable options are \code{"CLA"} (Complete Linear),
 \code{"EM"} (Ensemble Mean), \code{"ES"} (Ensemble Stability), and
 \code{"EE"} (Ensemble Exponential)}

\item{stability.metric}{string indicating the type of stability metric.
Avialable options are \code{"jaccard"} (Jaccard Index/Tanimoto Distance),
 \code{"sorensen"} (Dice-Sorensen's Index), \code{"ochiai"} (Ochiai's Index),
 \code{"pof"} (Percent of Overlapping Features), \code{"kuncheva"} (Kuncheva's Stability Measures),
 \code{"spearman"} (Spearman Rank Correlation), and \code{"canberra"} (Canberra Distance)}

\item{optimize}{Logical argument determining if each model should be optimized.
Default \code{"optimize = TRUE"}}

\item{optimize.resample}{Logical argument determining if each resample should be re-optimized.
Default \code{"optimize.resample = FALSE"} - Only one optimization run, subsequent models use initially
determined parameters}

\item{tuning.grid}{Optional list of grids containing parameters to optimize for each algorithm.
Default \code{"tuning.grid = NULL"} lets function create grid determined by \code{"res"}}

\item{k.folds}{Number of folds generated during cross-validation.  May optionally be set to \code{"LOO"} for
leave-one-out cross-validation.  Default \code{"k.folds = 10"}}

\item{repeats}{Number of times cross-validation repeated.  Default \code{"repeats = 3"}}

\item{resolution}{Optional - Resolution of model optimization grid.  Default \code{"res = 3"}}

\item{metric}{Criteria for model optimization.  Available options are \code{"Accuracy"} (Predication Accuracy),
\code{"Kappa"} (Kappa Statistic), and \code{"AUC-ROC"} (Area Under the Curve - Receiver Operator Curve)}

\item{model.features}{Logical argument if should have number of features selected to be determined
by the individual model runs.  Default \code{"model.features = FALSE"}}

\item{allowParallel}{Logical argument dictating if parallel processing is allowed via foreach package.
Default \code{allowParallel = FALSE}}

\item{verbose}{Logical argument if should output progress}

\item{...}{Extra arguments that the user would like to apply to the models}
}
\value{
\item{Methods}{Vector of models fit to data}

\item{performance}{Performance metrics of each model and bootstrap iteration}

\item{RPT}{Robustness-Performance Trade-Off as defined in Saeys 2008}

\item{features}{List concerning features determined via each algorithms feature selection criteria.}

\itemize{
 \item{metric: Stability metric applied}
 \item{features: Matrix of selected features}
 \item{stability: Matrix of pairwise comparions and average stability}
 }

\item{stability.models}{Function perturbation metric - i.e. how similar are the features selected
by each model.}

\item{all.tunes}{If \code{"optimize.resample = TRUE"} then returns list of
optimized parameters for each bagging and bootstrap interation.}

\item{final.best.tunes}{If \code{"optimize.resample = TRUE"} then returns list of
optimized parameters for each bootstrap of the bagged models refit to aggregated selected features.}

\item{specs}{List with the
following elements:}

\itemize{
 \item{total.samples: Number of samples in original dataset}
 \item{number.features: Number of features in orginal dataset}
 \item{number.groups: Number of groups}
 \item{group.levels: The specific levels of the groups}
 \item{number.observations.group: Number of observations in each group}}
}
\description{
Applies ensembles of models to high-dimensional data to both classify and determine important
features for classification.  The function bootstraps a user-specified number of times to facilitate
stability metrics of features selected thereby providing an important metric for biomarker investigations,
namely whether the important variables can be identified if the models are refit on 'different' data.
}
\author{
Charles Determan Jr
}
\references{
Saeys Y., Abeel T., et. al. (2008) \emph{Machine Learning and Knowledge Discovery in Databases}.
313-325. http://link.springer.com/chapter/10.1007/978-3-540-87481-2_21
}

